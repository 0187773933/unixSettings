#!/usr/bin/python

import requests , sys , os
from bs4 import BeautifulSoup

arg_names = [ "bindir" ,  "url" , "savename" ]
args = dict( zip( arg_names , sys.argv ) )

def requests_start_url(start_url):
	try:
		response = requests.get(start_url)
		html = response.text
		return html
	except RequestException:
		print('Opps! Occurred error')
		return None


def find_photo_url(requests_url):
	soup = BeautifulSoup(requests_url, 'lxml')
	photo_url = soup.find("meta", property="og:image")
	#print(photo_url)
	#print(photo_url['content'])
	return photo_url["content"]


def downloader( photo_url ):
	#extract some character of photo_url in order to name the photo
	global args
	if "savename" in args:
		args[ "savename" ] = os.path.join( os.getcwd() , args[ "savename" ] + ".jpg" )
	else:
		args[ "savename" ] = os.path.join( os.getcwd() , args[ "id" ] + ".jpeg" )
	print( '\nPhoto Path is: ' + args[ "savename" ] )
	requests_url = requests.get( photo_url )
	f = open( args[ "savename" ] , 'ab' )
	f.write( requests_url.content )
	print( 'Processing' )
	f.close()
	print( 'Download complete' )

def main():
	global args
	args[ "id" ] = args[ "url" ].split( "p/" )
	if len( args[ "id" ] ) > 1:
		args[ "id" ] = args[ "id" ][ 1 ]
	else:
		args[ "id" ] = args[ "id" ][ 0 ]
	args[ "id" ] = args[ "id" ].split( "/" )[ 0 ]
	args[ "url" ] = "https://www.instagram.com/p/" + args[ "id" ]
	requests_url = requests_start_url( args[ "url" ] )
	args[ "realurl" ] = find_photo_url( requests_url )
	downloader( args[ "realurl" ] )
	print( "" )
	print( args )
	print( "" )


if __name__ == '__main__':
	main()
